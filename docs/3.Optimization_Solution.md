### Automated Prompt Optimization

DSPy treats prompt construction as a machine learning problem - it automatically searches for the best prompts and few-shot examples using your data and metrics.

#### We have 4 types of optimizers

- **Automatic Few-Shot Learning**
These optimizers extend the signature by automatically generating and including optimized examples within the prompt sent to the model, implementing few-shot learning. 
    - For the sake of this demonstration, we will be using `BootstrapFewShot`
    - Take a look at [bootstrap_example.py](../dspy/3.bootstrap_example.py)
    - We are classifying support tickets to actual category
    - We got some `training` and `test` dataset
    - We will be using the `baseline router` and evaluate it on `test` dataset.
    - Later, we will be using the `optimized router` and evaluate it on `test` dataset.
    - Compare the accuracy of both routers and check which one works best for the use case.
    - you can version control your programs and load them anytime. This Optimizer just figures what examples are best for your use case.
    - When comparing with traditional propmt engineering, in case we have to go with few-shot approach, we have to manually select examples and change prompts etc. This is most tiring and

- **Automatic Instruction Optimization**
These optimizers produce optimal instructions for the prompt and, in the case of MIPROv2 can also optimize the set of few-shot demonstrations.
    - For the sake of this demonstration, we will be using `COPRO`.
    - With COPRO, we're not just classifying emails - we're automatically discovering the optimal reasoning strategies for understanding customer intent. And we achieved this without any manual prompt engineering or fine-tuning
    - Take a look at [copro_example.py](../dspy/4.copro_example.py)
    - open the saved checkpoint file to understand what is the system instruction that is generated automatically for us.